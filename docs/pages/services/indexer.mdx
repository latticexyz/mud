# Indexer

The MUD Indexer is an offchain indexer for onchain applications built with MUD.

## Why an offchain indexer?

Reads with onchain apps can be tricky.
What does it mean to be able to query the Ethereum network?
Technically, given a node with a fully synced state, we can explore just about everything using the EVM, but the “exploring” would be looking at raw storage slots for accounts corresponding to smart contracts.
A way around this exists by providing view functions on smart contracts: these effectively are just wrappers around raw storage and expose a more friendly API.
Instead of having to figure out where the balances for an account are stored in the storage tree, we now can call a function that does the lookup via Solidity via an RPC endpoint.

The issue with view functions is that for any sophisticated application the calls needed to get the “full picture” of the state from the chain are very complex.
Servicing so many view function calls also creates the need to run a set of dedicated nodes instead of relying on a third-party provider's free tier.

The MUD indexer solves this problem by listening to the MUD store events to automatically replicate the entire onchain state in a relational database.
Having such a database allows clients to quickly and efficiently query the onchain data.

## Installation

These environment variables need to be provided to the indexer to work:

| Type                      | Variable        | Meaning                                                                                                  | Sample value (using `anvil` running on the host)          |
| ------------------------- | --------------- | -------------------------------------------------------------------------------------------------------- | --------------------------------------------------------- |
| Needed                    | RPC_HTTP_URL    | The URL to access the blockchain using HTTP                                                              | http://host.docker.internal:8545 (when running in Docker) |
| Optional                  | RPC_WS_URL      | The URL to access the blockchain using WebSocket                                                         |
| Optional                  | START_BLOCK     | The block to start indexing from. The block in which the `World` contract was deployed is a good choice. | 1                                                         |
| Optional                  | DEBUG=mud:\*    | Turn on debugging                                                                                        |                                                           |
| Optional, only for SQLite | SQLITE_FILENAME | Name of database                                                                                         | `indexer.db`                                              |
| Required for PostgreSQL   | DATABASE_URL    | URL for the database, of the form `postgres://<host>/<database>`                                         |

### Running directly with SQLite

To run the indexer directly on your computer using SQLite:

1. Start a `World` to index.
   An easy way to do this is to [use a TypeScript template](/templates/typescript/getting-started) in a separate command line window.

1. Install the indexer.

   ```bash copy
   pnpm install @latticexyz/store-indexer@next
   ```

1. Set `RPC_HTTP_URL` and run the indexer.

   ```bash copy
   export RPC_HTTP_URL=http://127.0.0.1:8545
   pnpm sqlite-indexer
   ```

**Note:** The `indexer.db` is persistent if you stop and restart the indexer.
If that is not the desired behavior (for example, because you restarted the blockchain itself), delete it before starting the indexer.

### Running directly with PostgreSQL storage

This is the method to use PostgreSQL as merely a data storage solution.
It has better performance, but the format of the data in PostgreSQL is opaque, you have to use our front end to understand the data.

1. Start a `World` to index.
   An easy way to do this is to [use a TypeScript template](/templates/typescript/getting-started) in a separate command line window.

1. Install the indexer.

   ```bash copy
   pnpm install @latticexyz/store-indexer@next
   ```

1. Set the environment variables and start the indexer.

   ```bash copy
   export RPC_HTTP_URL=http://127.0.0.1:8545
   export DATABASE_URL=postgres://127.0.0.1/postgres
   pnpm postgres-indexer
   ```

1. Run the front end, which is responsible for serving the data, in a separate command-line window.

   ```bash copy
   export DATABASE_URL=postgres://127.0.0.1/postgres
   pnpm postgres-frontend
   ```

### Running directly with PostgreSQL queries

This is the method to store the table information in PostgreSQL, with a table corresponding to each MUD table.
Use this method when you want to use SQL queries to view the data.

1. Start a `World` to index.
   An easy way to do this is to [use a TypeScript template](/templates/typescript/getting-started) in a separate command line window.

1. Install the indexer.

   ```bash copy
   pnpm install @latticexyz/store-indexer@next
   ```

1. Set the environment variables and start the indexer.

   ```bash copy
   export RPC_HTTP_URL=http://127.0.0.1:8545
   export DATABASE_URL=postgres://127.0.0.1/postgres
   pnpm postgres-decoded-indexer
   ```

1. To verify the installation, but `psql` and then:

   - List the schemas.

     ```sql copy
     \dn
     ```

     Result:

     ```
                                     List of schemas
                          Name                         |       Owner
     --------------------------------------------------+-------------------
     0x6e9474e9c83676b9a71133ff96db43e7aa0a4342__      | qbzzt
     0x6e9474e9c83676b9a71133ff96db43e7aa0a4342__store | qbzzt
     0x6e9474e9c83676b9a71133ff96db43e7aa0a4342__world | qbzzt
     mud                                               | qbzzt
     public                                            | pg_database_owner
     (5 rows)
     ```

   - Connect to the schema for your world.

     ```sql copy
     set search_path to "0x6e9474e9c83676b9a71133ff96db43e7aa0a4342__";
     ```

   - Get the list of tables.

     ```sql copy
     \dt
     ```

     Result (When using the React template):

     ```
                             List of relations
                       Schema                      | Name  | Type  | Owner
     ----------------------------------------------+-------+-------+-------
     0x6e9474e9c83676b9a71133ff96db43e7aa0a4342__  | tasks | table | qbzzt
     (1 row)
     ```

   - Read the actual data.

     ```sql copy
     select * from tasks;
     ```

     Result:

     ```
                                   key                                  | created_at | completed_at |    description     |                            __key_bytes                             | __last_updated_block_number
     --------------------------------------------------------------------+------------+--------------+--------------------+--------------------------------------------------------------------+-----------------------------
     \x3100000000000000000000000000000000000000000000000000000000000000 | 1702401236 |            0 | Walk the dog       | \x3100000000000000000000000000000000000000000000000000000000000000 |                          17
     \x5e9c11602057fbf149cca23095b1863f7ffa8d0d0bd9434005a344ad612488a7 | 1702401238 |            0 | Take out the trash | \x5e9c11602057fbf149cca23095b1863f7ffa8d0d0bd9434005a344ad612488a7 |                          17
     \x0c9151148be227a42be8d3e3e7e61da28a532f2340b0ad9ca8bc747703ec2417 | 1702401238 |   1702401238 | Do the dishes      | \x0c9151148be227a42be8d3e3e7e61da28a532f2340b0ad9ca8bc747703ec2417 |                          17
     (3 rows)
     ```

### Docker

The indexer Docker image is available [on github](https://github.com/latticexyz/mud/pkgs/container/store-indexer).

There are several ways to provide the environment variables to `docker run`:

- On the command line you can specify `-e <variable>=<value>`.
  You specify this after the `docker run`, but before the name of the image.
- You can also write all the environment variables in a file and specify it using `--env-file`.
  You specify this after the `docker run`, but before the name of the image.
- Both [Docker Compose](https://docs.docker.com/compose/) and [Kubernetes](https://kubernetes.io/) have their own mechanisms for starting docker containers with environment variables.

The easiest way to test the indexer is to [run the template as a world](/templates/typescript/getting-started) in a separate command-line window.

#### SQLite

The command to start the indexer in SQLite mode is `pnpm start:sqlite`.
To index an `anvil` instance running to the host, use:

```sh copy
docker run \
  --platform linux/amd64 \
  -e RPC_HTTP_URL=http://host.docker.internal:8545 \
  -p 3001:3001  \
  ghcr.io/latticexyz/store-indexer:latest  \
  pnpm start:sqlite
```

However, this creates a docker container with a state, the SQLite database file.
If we start a new container with the same image and parameters, it is going to have to go back to the start of the blockchain, which depending on how long the blockchain has been in use may be a problem.
We can solve this with [volumes](https://docs.docker.com/storage/volumes/):

1. Create a docker volume for the SQLite database file.

   ```sh copy
   docker volume create sqlite-db-file
   ```

1. Run the indexer container using the volume.

   ```sh copy
   docker run \
      --platform linux/amd64 \
      -e RPC_HTTP_URL=http://host.docker.internal:8545 \
      -e SQLITE_FILENAME=/dbase/indexer.db \
      -v sqlite-db-file:/dbase \
      -p 3001:3001  \
      ghcr.io/latticexyz/store-indexer:latest  \
      pnpm start:sqlite
   ```

1. You can stop the docker container and restart it, or start a separate container using the same database.

1. When you are done, you have to delete the docker containers that used it before you can delete the volume.
   You can use these commands:

   ```sh copy
   docker rm `docker ps -a --filter volume=sqlite-db-file -q`
   docker volume rm sqlite-db-file
   ```

   **Note:** You should do this every time you restart the blockchain.
   Otherwise your index will include data from multiple blockchains, and make no sense.

#### PostgreSQL as storage

The command to start the indexer in PostgreSQL mode is `pnpm start:postgres`.
This command starts both the indexer and the front end.

1. The docker instance identifies itself to PostgreSQL as `root`.
   To give this user permissions on the database, enter `psql` and run this command.

   ```sql copy
   CREATE ROLE root SUPERUSER LOGIN;
   ```

   **Note:** This is assuming a database that is isolated from the internet and only used by trusted entities.
   In a production system you will use at least a password as authentication, and limit the user's authority.

1. Start the docker container.
   For example, to index an `anvil` instance running to the host to the database `postgres` on the host, use.

   ```sh copy
   docker run \
     --platform linux/amd64 \
     -e RPC_HTTP_URL=http://host.docker.internal:8545 \
     -e DATABASE_URL=postgres://host.docker.internal/postgres \
     -p 3001:3001  \
     ghcr.io/latticexyz/store-indexer:latest  \
     pnpm start:postgres
   ```

   If you want to create additional front ends (for reliability and load balancing), use these commands:

   ```sh copy
   HOST_PORT=3002
   docker run \
     --platform linux/amd64 \
     -e DATABASE_URL=postgres://host.docker.internal/postgres \
     -p $HOST_PORT:3001  \
     ghcr.io/latticexyz/store-indexer:latest  \
     node dist/bin/postgres-frontend.js
   ```

#### PostgreSQL for queries

The command to start the indexer in PostgreSQL mode is `pnpm start:postgres-decoded`.
This command starts both the indexer and the front end.

1. The docker instance identifies itself to PostgreSQL as `root`.
   To give this user permissions on the database, enter `psql` and run this command.

   ```sql copy
   CREATE ROLE root SUPERUSER LOGIN;
   ```

   **Note:** This is assuming a database that is isolated from the internet and only used by trusted entities.
   In a production system you will use at least a password as authentication, and limit the user's authority.

1. Start the docker container.
   For example, to index an `anvil` instance running to the host to the database `postgres` on the host, use.

   ```sh copy
   docker run \
     --platform linux/amd64 \
     -e RPC_HTTP_URL=http://host.docker.internal:8545 \
     -e DATABASE_URL=postgres://host.docker.internal/postgres \
     -p 3001:3001  \
     ghcr.io/latticexyz/store-indexer:latest  \
     pnpm start:postgres-decoded
   ```

### Verification

If you use either SQLite or PostgreSQL with the front-end (using PostgreSQL only as storage), you can run this command to test the indexer.

```sh copy
curl 'http://localhost:3001/trpc/findAll?batch=1&input=%7B%220%22%3A%7B%22json%22%3A%7B%22chainId%22%3A31337%2C%22address%22%3A%220x6e9474e9c83676b9a71133ff96db43e7aa0a4342%22%7D%7D%7D' | jq
```

The result should be nicely formatted (and long) JSON output with all the data stored in the `World`.

<details>

<summary>Where does this URL come from?</summary>

The URL has these parameters:

| Parameter | Value                 | Explanation                                    |
| --------- | --------------------- | ---------------------------------------------- |
| Server    | http://localhost:3001 | By default the indexer listens on port 3001    |
| Path      | trpc/findAll          | Return all entries (based on the input filter) |
| `batch`   | `1`                   | A required field                               |
| `input`   | `%7B%22 ... %7D%7D`   | See below                                      |

The input is the JSON filter that tells the server what we need.
It is [URL encoded](https://en.wikipedia.org/wiki/Percent-encoding), you can decode it [using an online calculator](https://www.urldecoder.org/).

```json
{
  "0": {
    "json": {
      "chainId": 31337,
      "address": "0x6e9474e9c83676b9a71133ff96db43e7aa0a4342"
    }
  }
}
```

Meaning that query 0 is for everything in the `World` at address `0x6e9474e9c83676b9a71133ff96db43e7aa0a4342`, on the chain with chain ID `31337`.

</details>

## Some examples

### SQLite to view the tasks from the React template

- Start the indexer.

  ```sh copy
  pnpm install @latticexyz/store-indexer@next
  export RPC_HTTP_URL=http://127.0.0.1:8545
  pnpm sqlite-indexer
  ```

- Read the data.

  ```sh copy
  curl 'http://localhost:3001/trpc/findAll?batch=1&input=%7B%220%22%3A%7B%22json%22%3A%7B%22chainId%22%3A31337%2C%22address%22%3A%220x6e9474e9c83676b9a71133ff96db43e7aa0a4342%22%7D%7D%7D' | \
  jq '.[0].result.data.json.tables' | \
  jq -c '.[] | select (.name=="Tasks")' | \
  jq .records | more
  ```

### Postgres to read data from SkyStrife season 0

1. If necessary, start Docker and PostgreSQL.

1. Start the Postgres Docker container.

   ```sh copy
   docker run \
      --platform linux/amd64 \
      -e RPC_HTTP_URL=https://rpc.holesky.redstone.xyz \
      -e RPC_WS_URL=wss://rpc.holesky.redstone.xyz/ws \
      -e DATABASE_URL=postgres://host.docker.internal/postgres \
      -e START_BLOCK=895629 \
      -p 3001:3001  \
      ghcr.io/latticexyz/store-indexer:latest  \
      pnpm start:postgres
   ```

1. It will take a while until the indexer synchronizes all the way to the present.
   However, we can already read information and it will give us the latest it has.

1. Read the data from the indexer.

   ```sh copy
   INDEXER_URL=http://localhost:3001/trpc
   WORLD_ADDRESS=0x7203e7adfdf38519e1ff4f8da7dcdc969371f377
   CHAIN_ID=17001
   JSON='{"0":{"json":{"chainId":'$CHAIN_ID', "address":"'$WORLD_ADDRESS'"}}}'
   ENCODED_JSON=`echo "console.log(encodeURI('$JSON'))" | node`
   curl $INDEXER_URL'/findAll?batch=1&input='$ENCODED_JSON > data.json
   ```

1. Obtain the list of tables.

   ```sh copy
   TABLES=`cat data.json | jq '.[0].result.data.json.tables'`
   echo $TABLES | jq '.[].name'
   ```

1. Get the combatant entities.

   ```sh copy
   echo $TABLES | jq '.[] | select (.name=="Combat")'
   ```
